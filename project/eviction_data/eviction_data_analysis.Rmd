---
title: "final_project.rmd"
author: "Taylor Nichols"
date: "2025-04-24"
output: html_document
---
NOTE FOR DEREK: For my tests, start at ## Question 1 tests


Kinds of tests I want to do: I think it would be useful to see if there is a correlation between evictions and landlord violations, and then do a linear regression. Once I get my home owner data loaded in, I would also like to see what the relationship between each of the three variables is (we can do that with a multiple regression, right? or just scatterplots on both of them?)

What I really want to get at is how much more likely things are.

I also want to look at eviction rates over time -- maybe weekly and monthly? Would it be worthwhile to look at when spikes occurred? probably. I wish i had more data to do this on but alas I do not.

I also need to pull in the census data/overall stats. Is it worth pulling in census tract level data instead? I kind of feel like that might be more illuminating but also more work which I don't really feel like I need right now. I'll ruminate on it.

I also think it would be wortwhile to look at this at the building level to identify eviction hot spots and how that has changed over time but I don't really know if that's a stats question.

Problems I am having so far: Mostly I am just struggling to get the data all cleaned. The eviction data is a mess. I am getting close but I just need to sit down and have some heads down time on it so I can start my analyses. Which I will do this weekend.

Evictions data comes from the DC Office of the Tenant Advocate. The violations data came from the DC Dept of Buildings Violations and Abatement Tool. <https://dataviz1.dc.gov/t/OCTO/views/DOBPublicDashboard/ViolationsAbatementLVT?%3AshowAppBanner=false&%3Adisplay_count=n&%3AshowVizHome=n&%3Aorigin=viz_share_link&%3Aembed=yes&%3Atoolbar=no>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
```

```{r load libraries}
library(tidyverse)
library(lubridate)
library(janitor)
library(ggplot2)
library(readODS)
library(vcd)
library(tidygeocoder)
```

## This section is cleaning data and getting it ready to analyze

```{r read in data}
eviction_data <- read_csv("eviction_data_ward_geocodio.csv")
df_violations <- read_delim("detailed_landlord_violations.csv", 
                           delim = "\t",  # Try tab as delimiter
                           locale = locale(encoding = "UTF-16LE"),
                           show_col_types = FALSE) |> clean_names() |>
                            mutate(created_date = case_when(str_detect(created_date, "^\\d{1,2}/\\d{1,2}/\\d{4}$") ~ mdy(created_date)))

homeowners_one <- read_ods("ods_one.ods")
homeowners_two <- read_ods("ods_2.ods")
homeowners_three <- read_ods("ods_3.ods")
homeowners_four <- read_ods("ods_4.ods")
census <- read_csv("census_data.csv")
```

```{r}
dc_homeowners <- bind_rows(homeowners_one, homeowners_two, homeowners_three, homeowners_four)
```


```{r}
violations_zip <- df_violations |>
  select(violation_address) |>
  distinct() |>
  mutate(full_address = paste(violation_address, "Washington, DC")) |>
  geocode(
    address = full_address,
    method = "geocodio",
    full_results = TRUE  # Add this parameter to get all available data
  )
```

```{r}
violations_zip <- violations_zip |>
  select(violation_address, address_components.postdirectional, address_components.zip, lat, long) |>
  rename(quadrant = address_components.postdirectional, zipcode = address_components.zip)
```

```{r}
df_violations <- df_violations |>
  left_join(violations_zip, by = c("violation_address"))
```

Let's look at our eviction data

```{r}
eviction_data
```

Our eviction data is pretty messy. It spans from Nov 2023 to June 2025. It includes address, case number, eviction date, and other geocoding info.

Now let's look at our violations data:

```{r}
df_violations
```

This data spans from march 2018 to march 2025. We also have owner, violation address, unit, cap_id (not sure what this is), floor, location, violation and fine amt.

I think we can assume that addresses with units are likely owned by the same owner (unless they're condos -- maybe this isn't a safe assumption, actually.) Our landlord data is stored with unit as a separate column, so let's make our data format match.

```{r}
eviction_data_clean <- eviction_data |>
  select(case_number, defendant_address, quad, zipcode, eviction_date, full_address, lat, lng, ward, year, month_name)
```

```{r}
#I used Claude to help me write all this cleaning code
eviction_data_clean <- eviction_data_clean %>%
  mutate(
    # First, separate the unit information from the base address
    base_address = case_when(
      # Extract everything before UNIT, APT, etc.
      str_detect(defendant_address, "(?i)\\s+(UNIT|APT|APARTMENT|SUITE|STE)\\s+[A-Z0-9-]+") ~
        str_trim(str_replace(defendant_address, 
                           "(?i)\\s+(UNIT|APT|APARTMENT|SUITE|STE)\\s+[A-Z0-9-]+.*$", "")),
      
      # If no UNIT/APT keyword, extract everything before a comma or #
      str_detect(defendant_address, "[,#]") ~
        str_trim(str_replace(str_extract(defendant_address, "^[^,#]+"), "\\s+$", "")),
      
      # Default: use the whole address if no unit information is found
      TRUE ~ defendant_address
    ),
    
    # Extract unit information
    unit_info = case_when(
      # Match "UNIT 123" format (works for UNIT 202, UNIT 409, UNIT 101, etc.)
      str_detect(defendant_address, "(?i)\\s+UNIT\\s+\\d+") ~
        str_trim(str_extract(defendant_address, "(?i)\\s+UNIT\\s+\\d+")),
      
      # Match "APT 123" format
      str_detect(defendant_address, "(?i)\\s+APT(ARTMENT)?\\s+\\d+") ~
        str_trim(str_extract(defendant_address, "(?i)\\s+APT(ARTMENT)?\\s+\\d+")),
      
      # Match "STE 123" format
      str_detect(defendant_address, "(?i)\\s+S(UI)?TE\\s+\\d+") ~
        str_trim(str_extract(defendant_address, "(?i)\\s+S(UI)?TE\\s+\\d+")),
      
      # Match "#123" format
      str_detect(defendant_address, "#\\s*[A-Z0-9-]+") ~
        str_trim(str_extract(defendant_address, "#\\s*[A-Z0-9-]+")),
      
      # Match comma followed by unit information
      str_detect(defendant_address, ",\\s*(?i)(UNIT|APT|APARTMENT|SUITE|STE)\\s+\\d+") ~
        str_trim(str_extract(defendant_address, "(?i)(UNIT|APT|APARTMENT|SUITE|STE)\\s+\\d+")),
      
      # Default: NA if no unit information is found
      TRUE ~ NA_character_
    ),
    
    # Extract just the unit number (without the UNIT/APT prefix)
    clean_unit = case_when(
      !is.na(unit_info) & str_detect(unit_info, "(?i)(UNIT|APT|APARTMENT|SUITE|STE)\\s+\\d+") ~
        str_trim(str_replace(unit_info, "(?i)(UNIT|APT|APARTMENT|SUITE|STE)\\s+", "")),
      
      !is.na(unit_info) & str_detect(unit_info, "#\\s*\\d+") ~
        str_trim(str_replace(unit_info, "#\\s*", "")),
      
      TRUE ~ NA_character_
    )
  ) %>%
  # Now clean and standardize the base address
  mutate(
    clean_address = str_replace_all(base_address, "[,\\.]+", ""),
    
    # Standardize street suffixes
    clean_address = case_when(
      str_detect(clean_address, "(?i)\\s+STREET(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+STREET(\\s+|$)", " ST "),
      str_detect(clean_address, "(?i)\\s+AVENUE(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+AVENUE(\\s+|$)", " AVE "),
      str_detect(clean_address, "(?i)\\s+CIRCLE(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+CIRCLE(\\s+|$)", " CIR "),
      str_detect(clean_address, "(?i)\\s+BOULEVARD(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+BOULEVARD(\\s+|$)", " BLVD "),
      str_detect(clean_address, "(?i)\\s+COURT(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+COURT(\\s+|$)", " CT "),
      str_detect(clean_address, "(?i)\\s+DRIVE(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+DRIVE(\\s+|$)", " DR "),
      str_detect(clean_address, "(?i)\\s+LANE(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+LANE(\\s+|$)", " LN "),
      str_detect(clean_address, "(?i)\\s+ROAD(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+ROAD(\\s+|$)", " RD "),
      str_detect(clean_address, "(?i)\\s+PLACE(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+PLACE(\\s+|$)", " PL "),
      str_detect(clean_address, "(?i)\\s+TERRACE(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+TERRACE(\\s+|$)", " TER "),
      str_detect(clean_address, "(?i)\\s+HIGHWAY(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+HIGHWAY(\\s+|$)", " HWY "),
      str_detect(clean_address, "(?i)\\s+PARKWAY(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+PARKWAY(\\s+|$)", " PKWY "),
      str_detect(clean_address, "(?i)\\s+WAY(\\s+|$)") ~ 
        str_replace_all(clean_address, "(?i)\\s+WAY(\\s+|$)", " WY "),
        
      # Default: keep the address as is
      TRUE ~ clean_address
    ),
    
    # Clean up any extra spaces
    clean_address = str_trim(str_replace_all(clean_address, "\\s+", " "))
  )

eviction_data_clean <- eviction_data_clean %>%
  mutate(
    # Extract the street suffix pattern
    suffix_pattern = "(?i)\\s+(ST|AVE|BLVD|CIR|CT|DR|LN|RD|PL|TER|HWY|PKWY|WY)\\b",
    
    # Check if there's any remaining text after the street suffix
    has_extra_text = str_detect(clean_address, paste0(suffix_pattern, "\\s+.+")),
    
    # For addresses with extra text after suffix, update columns
    temp_address = ifelse(has_extra_text,
                         str_extract(clean_address, paste0("^.*?", suffix_pattern)),
                         clean_address),
    
    temp_unit_info = ifelse(has_extra_text,
                           str_trim(str_replace(clean_address, paste0("^.*?", suffix_pattern, "\\s+"), "")),
                           NA_character_),
    
    # Update clean_address with just the part up to the suffix
    clean_address = ifelse(has_extra_text, str_trim(temp_address), clean_address),
    
    # Update unit_info with the extra text if unit_info was previously NA
    unit_info = case_when(
      has_extra_text & is.na(unit_info) ~ temp_unit_info,
      has_extra_text & !is.na(unit_info) ~ paste(unit_info, temp_unit_info, sep = " "),
      TRUE ~ unit_info
    ),
    
    # Update clean_unit to extract numbers from the new unit_info
    clean_unit = case_when(
      # Keep existing clean_unit if already set
      !is.na(clean_unit) ~ clean_unit,
      
      # Extract numbers/alphanumeric from remaining text
      !is.na(unit_info) & str_detect(unit_info, "[0-9A-Z]+") ~
        str_trim(str_extract(unit_info, "[0-9A-Z]+")),
      
      # Extract content from patterns like (D#202)
      !is.na(unit_info) & str_detect(unit_info, "\\([^)]*#([0-9A-Z]+)\\)") ~
        str_trim(str_extract(unit_info, "(?<=\\#)[0-9A-Z]+")),
      
      # Extract T1, D2, etc. type patterns
      !is.na(unit_info) & str_detect(unit_info, "[A-Z][0-9]+") ~
        str_trim(str_extract(unit_info, "[A-Z][0-9]+")),
      
      TRUE ~ NA_character_
    )
  ) %>%
  # Clean up the temporary columns
  select(-suffix_pattern, -has_extra_text, -temp_address, -temp_unit_info) |>
  filter(!str_detect(full_address, "\\bnan\\b")) |>
    filter(!str_detect(full_address, "VACANT LOT"))
```

The evictions data is still pretty messy. Units will need more cleaning, but at least we can play around with base address now.

```{r}
df_violations_clean <- df_violations |>
  select(s_no, owner, violation_address, unit, zipcode, created_date, location, violation)
```

Let's make a df that shows us how many violations have happened at each street address and how many units there are.

```{r}
# Count total violations and unique units per address
df_violations_summary <- df_violations_clean |>
  group_by(violation_address, zipcode) |>
  summarise(
    total_violations = n(),
    unique_violation_units = n_distinct(unit, na.rm = TRUE),
    unit_violation_list = paste(unique(na.omit(unit)), collapse = ", ")
  )
```

Let's see how many violations there are per owner for fun.

```{r}
df_violations_clean |>
  group_by(owner) |>
  summarise(count=n()) |>
  arrange(desc(count))
```
Now, let's join our violations to our evictions data. tabling this for now because i need to do some more data cleaning to do it.

```{r}
evictions_summary <- eviction_data_clean |>
  # First combine clean_address and quad (only where quad exists)
  mutate(full_address = ifelse(
    !is.na(quad),
    paste(clean_address, quad),
    clean_address
  )) |>
  # Then continue with your grouping and summarizing
  group_by(full_address, zipcode, ward) |>
  summarise(
    total_evictions = n(),
    unique_eviction_units = n_distinct(clean_unit, na.rm = TRUE),
    eviction_unit_list = toString(na.omit(unique(clean_unit)))
  )

# Rename the address column in violations summary to match your naming convention
df_violations_summary <- df_violations_summary |>
  rename(full_address = violation_address)
```

```{r}
summary_df <- full_join(df_violations_summary, evictions_summary, by = c("full_address")) |>
    mutate(
    total_violations = replace_na(total_violations, 0),
    total_evictions = replace_na(total_evictions, 0))
```

```{r}
number_of_evictions <- summary_df |>
  group_by(total_evictions) |>
  summarise(number_of_buildings= n())

total_violations <- summary_df |>
  group_by(total_violations) |>
  summarise(number_of_buildings=n())
```

# Data analysis section

## Questions to explore:
Question 1: What is the relationship between scheduled evictions and landlord violations? Is there a correlation between the two?
To answer this I will need to compare whether a property has had a scheduled eviction and a landlord violation (yes/no). I will also need to compare the NUMBER of evictions with the number of landlord violations. I think I can scatterplot both of these (?)
as landlord violations increase is it more likely that they will have an eviction?
subset these outliers out

i can run a chi-square test on wards if i can pull the old evictions data

could run on landord violations

Question 2: What is the relationship between the number of landlord citations and home ownership? Are properties owned by LLCS or LPs more likely to have citations and have MORE citations than properties listed under an individual's name? What types of landlords/what landlords are most likely to have citations? Who are the "worst offenders"?
ANOVA - differences within groups


To answer this I will need a dataframe that tells me the number of citations at a property under each owner. I can get the number of citations under each owner from the citations data, but I need to use the dc homeowners data to determine properties with no citations.
dont neeed to make binary for that 
between groups could be percentage, rate, etc.

My hypothesis: Property owners/LLCs with many properties are more likely to have citations at their properties than smaller landlords.

Question 3: As landlord violations increase is it more likely that they will have an eviction? - This can be a regression model - might be logsitic - let's ask gemini, should we do linear or logistic?
 
## Tests to run:
Question 1:
- Scatterplot with a best fit line to look at relationship between scheduled evictions and landlord violations
- Chi-square test to see if evictions are more likely to happen at addresses with housing violations
- Correlation - Use aggregate counts by zip code, ward or census tract to see if there's a relationship between number of violations and number of evictions

Regressions:
fallback - but if you're going to do a regression model
Does average amount of fine (take the amount for each cap_id) predicts the eviction count or rate for a ward or zip code?
Logistic regression - do specific factors influence evictions?

Saving these here as part of my project but not really stats questions, more supplementary analysis
- Look at this at the building level to identify eviction hot spots and how that has changed over time

outlier detection - lots of ways we can do this -
- Look at eviction rates over time -- maybe weekly and monthly?
z-scores and standard deviation


Question 2:
I am not 100 percent sure how to tackle this - my instinct is to make a bar chart of LLC/LP owned units and avg citations per unit, government-owned properties and citations per unit, and single person landlords and citations per unit to compare but I don't know that that really makes sense?

## Question 1 tests - DEREK START HERE

### Test 1. Scatterplot 

```{r}
summary_df |>
  ggplot(aes(x = total_violations, y = total_evictions)) +
  geom_point() +
  labs(x = "total_violations", y = "total_evictions", title = "evictions vs violations")
```
This doesn't really seem like it's super easy to analyze in this format given the few big outliers. It appears there isn't a super clear correlation between these two variables.

### Test 2. Correlation

Use aggregate counts by zip code, ward or census tract to see if there's a relationship between number of violations and number of evictions.

```{r}
evictions_zip <- evictions_summary |>
  group_by(zipcode) |>
  summarise(evictions = sum(total_evictions)) |>
  mutate(zipcode = as.character(zipcode))

violations_zip_agg <- df_violations_summary |>
  group_by(zipcode) |>
  summarise(violations = sum(total_violations))

aggregates <- full_join(evictions_zip, violations_zip_agg, by = c("zipcode"))
```

```{r}
aggregates |>
  ggplot(aes(x = violations, y = evictions)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  labs(x = "total_violations", y = "total_evictions", title = "evictions vs violations")
```
Ok this looks like something we can analyze more easily. 

### QUESTION: This is at the zip code level -- is it worth breaking it down to the tract level to get more data?
Second question: Is this just where the most houses are?

### Test 3: Linear regression

```{r}
model <- lm(`evictions` ~ `violations`, data = aggregates)
summary(model)
```
Looks like our regression model is a pretty good fit, although those residuals seem concerning to me. The p value is tiny, meaning the relationship here is extremely statistically significant. The adjusted R-squared tells us that 92 percent of our data can be explained by the relationship between these two -- basically the relationship is really strong.

Let's look at the residuals:
Not sure what's happening here but I will maybe try to dive into it later.
```{r}
aggregates$predicted <- predict(model)

# Calculate the residuals
aggregates <- aggregates |> 
  mutate(residual = `evictions` - predicted)

# Sort the data frame by the absolute value of the residuals in descending order
aggregates <- aggregates |>
  mutate(abs_residual = abs(residual)) |>
  arrange(desc(abs_residual))
```

Let's take a deep dive into evictions data.

### Test 4. Boxplot and ANOVA

```{r}
# Create boxplot
ggplot(evictions_summary, aes(x = ward, y = total_evictions, fill = ward)) +
  geom_boxplot() +
  labs(
    title = "Evictions by Ward",
    x = "Ward",
    y = "Evictions"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")
```
This is interesting - I don't really know what it means but Ward 6 is standing out much more than it did before. It looks like a handful of crazy outlier buildings are driving up the numbers for wards 7 and 8. What does the bigger yellow box mean for a boxplot exactly?

```{r}
# Create boxplot
ggplot(evictions_summary, aes(x = zipcode, y = total_evictions, fill = ward)) +
  geom_boxplot() +
  labs(
    title = "Evictions by Zipcode",
    x = "Zipcode",
    y = "Evictions"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")
```
Is this anything? I don't really know how to read this. I dropped it to Claude and it basically identified outliers and said the large yellow box for ward 6 means higher median rates which is interesting and wasn't immediately apparent to me within my data. 

That one random outlier in ward 1 with 50 evictions is something to look at. Ward 8 and ward 7 both have a handful of outliers driving up their numbers I think. Would be worth digging into those too.

```{r anova-test}
# Run one-way ANOVA
anova_result <- aov(total_evictions ~ ward, data = evictions_summary)
summary(anova_result)
```

The F-value is not crazy high, but I think given the smaller numbers we are working with it is still high. The p-value is very low, indicating the differences between zipcodes are statistically significant. 

## Task 5: Compare the differences between specific pairs

```{r post-hoc}
# Tukey's HSD test to see which specific pairs of college types differ
tukey_result <- TukeyHSD(anova_result)
print(tukey_result)
```
There is a ton of info here. I think I am going to call this good for now and dig into this more when I tackle the rest of my project.

I think from here we should bring in census data on race, median income and other factors at the tract level to determine what factors have the biggest influence on evictions. I also need to do some time analyses on evictions and calculate some z-scores. I feel pretty good about where I am at but would love some feedback if you see any red flags.

